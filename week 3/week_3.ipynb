{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Mathematics of Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages from previous "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic ML Workflow\n",
    "1. For each model, fit it to the *training set*\n",
    "2. Compute the error for each model on the *validation set*\n",
    "3. Select the model with the lowest validation error\n",
    "4. Compute the error of the final model on the *test set*\n",
    "\n",
    "### Questions to answer in ML project\n",
    "1. **(SELECTION)** Which of these models is the best?\n",
    "2. **(Future Performance)** How good should we expect the final model to be on unseen data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Diviser en trois - split 3 ways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the data\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "features, target = fetch_california_housing(as_frame=True, return_X_y=True)\n",
    "\n",
    "# split data into train, validation and test sets\n",
    "X_main, X_test, y_main, y_test = \\\n",
    "    train_test_split(features, target, test_size=0.2, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = \\\n",
    "    train_test_split(X_main, y_main, test_size=0.25, random_state=1) # As 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Building Flow as Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 34 s\n",
      "Wall time: 29.4 s\n",
      "387/387 [==============================] - 0s 787us/step\n",
      "129/129 [==============================] - 0s 831us/step\n",
      "129/129 [==============================] - 0s 787us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.32625776529312134"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = StandardScaler()\n",
    "sc.fit(X_train)\n",
    "X_train_sc = sc.transform(X_train)\n",
    "X_val_sc = sc.transform(X_val)\n",
    "X_test_sc = sc.transform(X_test)\n",
    "\n",
    "# For each model, fit it to the training set\n",
    "tf.random.set_seed(1234)\n",
    "model = Sequential([\n",
    "    Dense(30, activation=\"relu\"),\n",
    "    Dense(1, activation=\"exponential\")\n",
    "])\n",
    "model.compile(\"adam\", \"mse\")\n",
    "%time hist = model.fit(X_train_sc, y_train, epochs=100, verbose=False)\n",
    "\n",
    "# Compute the error for each model on the validation set and select model with lowest error\n",
    "mseExpAnnTrain = mean_squared_error(y_train, model.predict(X_train_sc))\n",
    "mseExpAnnVal = mean_squared_error(y_val, model.predict(X_val_sc))\n",
    "\n",
    "mseTrain = {\"Exp ANN\": mseExpAnnTrain}\n",
    "mseVal = {\"Exp ANN\": mseExpAnnVal}\n",
    "\n",
    "# Evaluate only the final model on the test set\n",
    "mean_squared_error(y_test, model.predict(X_test_sc))\n",
    "model.evaluate(X_test_sc, y_test, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Early Stopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 27.7 s\n",
      "Wall time: 23.5 s\n",
      "Keeping model at epoch #48.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "tf.random.set_seed(1234)\n",
    "model = Sequential([\n",
    "    Dense(30, activation=\"relu\"),\n",
    "    Dense(1, activation=\"exponential\")\n",
    "])\n",
    "model.compile(\"adam\", \"mse\")\n",
    "\n",
    "es = EarlyStopping(restore_best_weights=True, patience=10)\n",
    "\n",
    "%time hist = model.fit(X_train_sc, y_train, epochs=1_000, \\\n",
    "    callbacks=[es], validation_data=(X_val_sc, y_val), verbose=False)\n",
    "print(f\"Keeping model at epoch #{len(hist.history['loss'])-10}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loss curve\n",
    "plt.plot(hist.history[\"loss\"])\n",
    "plt.plot(hist.history[\"val_loss\"])\n",
    "plt.legend([\"Training\", \"Validation\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'file' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Other callbacks\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "tf.random.set_seed(1234)\n",
    "model = Sequential([\n",
    "    Dense(30, activation=\"relu\"),\n",
    "    Dense(1, activation=\"exponential\")\n",
    "])\n",
    "model.compile(\"adam\", \"mse\")\n",
    "\n",
    "# On Colab, save models to Google Drive.\n",
    "mc = ModelCheckpoint(\"best-model.h5\", monitor=\"val_loss\",\n",
    "        save_best_only=True)\n",
    "es = EarlyStopping(restore_best_weights=True, patience=5)\n",
    "\n",
    "hist = model.fit(X_train_sc, y_train, epochs=100, \\\n",
    "    validation_split=0.1, callbacks=[mc, es], verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Softmax activation for final layer\n",
    "- Creates a probability vector: Softmax(x) = $\\frac{e_i^x}{\\Sigma_j e^x_j}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data\n",
    "from sklearn.datasets import load_iris\n",
    "iris = load_iris()\n",
    "names = [\"SepalLength\", \"SepalWidth\", \"PetalLength\", \"PetalWidth\"]\n",
    "features = pd.DataFrame(iris.data, columns = names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target variable\n",
    "target = iris.target\n",
    "target = target.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2]\n",
      "[50 50 50]\n"
     ]
    }
   ],
   "source": [
    "# Frequency table\n",
    "classes, counts = np.unique(\n",
    "        target,\n",
    "        return_counts=True\n",
    ")\n",
    "print(classes)\n",
    "print(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 4\n",
      "Number of categories: 3\n"
     ]
    }
   ],
   "source": [
    "# Number of features and categories\n",
    "NUM_FEATURES = len(features.columns)\n",
    "NUM_CATS = len(np.unique(target))\n",
    "\n",
    "print(\"Number of features:\", NUM_FEATURES)\n",
    "print(\"Number of categories:\", NUM_CATS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to return a Keras model\n",
    "def build_model(seed=42):\n",
    "    tf.random.set_seed(seed)\n",
    "    return Sequential([\n",
    "        Dense(30, activation=\"relu\"),\n",
    "        Dense(NUM_CATS, activation=\"softmax\") # softmax for classification\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 4.08 s\n",
      "Wall time: 3.45 s\n",
      "Stopped after 170 epochs.\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.compile(\"adam\", \"SparseCategoricalCrossentropy\", \\\n",
    "        metrics=[\"accuracy\"])\n",
    "\n",
    "es = EarlyStopping(restore_best_weights=True, patience=50,\n",
    "        monitor=\"val_accuracy\")\n",
    "%time histES = model.fit(X_train, y_train, epochs=500, \\\n",
    "        validation_split=0.25, callbacks=[es], verbose=False);\n",
    "\n",
    "print(f\"Stopped after {len(histES.history['loss'])} epochs.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.34775248169898987, 0.9736841917037964]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate model - note it shows both loss and accuracy\n",
    "model.evaluate(X_test, y_test, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 34ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.00407997, 0.2903609 , 0.70555913],\n",
       "       [0.00736918, 0.33165058, 0.66098017],\n",
       "       [0.12062447, 0.6610642 , 0.21831135],\n",
       "       [0.05547402, 0.63195974, 0.3125663 ]], dtype=float32)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test.head(4))\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add 'keepdims=True' to get a column vector.\n",
    "np.argmax(y_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['virginica', 'virginica', 'versicolor', 'versicolor'], dtype='<U10')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show predictions as their class names\n",
    "iris.target_names[np.argmax(y_pred, axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder(sparse=False)\n",
    "\n",
    "y_train_oh = enc.fit_transform(y_train)\n",
    "y_test_oh = enc.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.29562538862228394, 0.9736841917037964]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classifier given one-hot outputs\n",
    "\n",
    "# Create the model (new loss function!)\n",
    "model = build_model()\n",
    "model.compile(\"adam\", \"CategoricalCrossentropy\", \\\n",
    "    metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit the model (new target variables)\n",
    "model.fit(X_train, y_train_oh, epochs=100, verbose=False);\n",
    "\n",
    "# Evaluate the model (new target variables)\n",
    "model.evaluate(X_test, y_test_oh, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Categorical boolean mask\n",
    "categorical_features_mask = (features.dtypes==object)\n",
    "\n",
    "#filter categorical columns using mask and turn into a list\n",
    "categorical_cols = features.columns[categorical_features_mask].tolist()\n",
    "categorical_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poisson Regression, Deviance and Loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The model\n",
    "Have $[(xi,yi)]_{i=1,…,n}$ for $ x_i∈R^{47} $ and $ y_i∈N_0 $.\n",
    "\n",
    "Assume the distribution\n",
    "\n",
    "$Y_i∼Poisson(λ(x_i))$\n",
    "\n",
    "We have $\\mathbb{E}Y_i=λ(x_i)$. The NN takes $x_i$ and predicts $\\mathbb{E}Y_i$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisson Probabilities \n",
    "Since the PMF of the N∼Poisson(λ) distribution is $\\mathbb{P}(N=k)=\\frac {λ^ke{−λ}} / {k!}$ then the PMF of $Y_i∼Poisson(λ(x_i))$ is\n",
    "$$\\mathbb{P}(Y_i=y_i)=\\frac{λ(x_i)^{y_i}e{−λ(xi)}} {y_i!}$$\n",
    "\n",
    "The likelihood of a sample is then:\n",
    "$$\\mathbb{P}(Y_1=y_1,…,Y_n=y_n)=\\prod_{i=1}^n \\mathbb{P}(Y_i=y_i)$$\n",
    "\n",
    "Therefore, the likelihod of $[(x_i,y_i)]_{i=1,…,n}$ is:\n",
    "$$L= \\prod_{i=1}^n \\frac{λ(x_i)^{y_i}e{−λ(xi)}} {y_i!}$$\n",
    "\n",
    "So the log-likelihood is:\n",
    "$$l = \\sum_{i=1}^n y_i log(\\lambda(x_i)) - \\lambda(x_i) - log(y_i!)$$\n",
    "\n",
    "We want to maximise the likelihood:\n",
    "$$\\lambda^* = ... = arg min_\\lambda \\frac {1} {n} \\sum_{i=1}^n \\lambda (x_i) - y_i log(\\lambda(x_i))$$\n",
    "\n",
    "Hence, Poisson Loss is:\n",
    "$$PoissonLoss = \\frac {1} {n} \\sum_{i=1}^n \\lambda (x_i) - y_i log(\\lambda(x_i))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisson Deviance\n",
    "$$ D = 2 \\sum_{i=1}^n y_i log(\\frac{y_i}{\\lambda(x_i)}) - (y_i-\\lambda(x_i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch gradient descent\n",
    "Go over all the training data\n",
    "\n",
    "    for i in range(numEpochs):\n",
    "      gradient = evaluate_gradient(loss_function, data, weights)\n",
    "      weights = weights - learningRate * gradient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stochastic gradient descent\n",
    "Pick a random training example\n",
    "\n",
    "    for i in range(numEpochs):\n",
    "      rnd.shuffle(data)\n",
    "      for example in data:\n",
    "        gradient = evaluate_gradient(loss_function, example, weights)\n",
    "        weights = weights - learningRate * gradient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini-batch gradient descent\n",
    "Take a group of training examples\n",
    "\n",
    "    for i in range(numEpochs):\n",
    "      rnd.shuffle(data)\n",
    "      for b in range(numBatches):\n",
    "        batch = data[b*batchSize:(b+1)*batchSize]\n",
    "        gradient = evaluate_gradient(loss_function, batch, weights)\n",
    "        weights = weights - learningRate * gradient\n",
    "\n",
    "Why?\n",
    "- We have to - data is too big\n",
    "- Faster - lots of quick noisy steps > a few slow super accurate steps\n",
    "- Noise helps us jump out of local minima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classes and Objects\n",
    "Often, the built-in types (int, double, list, etc.) aren’t enough. Need to make a new type of object.\n",
    "\n",
    "Example - students with name, zID, grades + shared way to calculate WAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Student:\n",
    "    def __init__(self, name, zID, grades): \n",
    "        self.name = name\n",
    "        self.zID = zID\n",
    "        self.grades = grades\n",
    "\n",
    "# The first parameter for each function inside a class is self."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding a method\n",
    "COURSE_CREDITS = {\"ACTL3143\": 6, \"ACTL5001\": 12}\n",
    "\n",
    "class Student:\n",
    "  def __init__(self, name, zID, grades):\n",
    "    self.name = name\n",
    "    self.zID = zID\n",
    "    self.grades = grades\n",
    "\n",
    "  def wam(self):\n",
    "    \"\"\"\n",
    "    Calculate the weighted average mark for this student.\n",
    "    \"\"\"\n",
    "    total_credits = 0\n",
    "    total_grade = 0\n",
    "    for course, grade in self.grades.items():\n",
    "      total_credits += COURSE_CREDITS[course]\n",
    "      total_grade += grade * COURSE_CREDITS[course]\n",
    "    return total_grade / total_credits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "don = Student(\"Don Quixote\", 111222,\n",
    "    {\"ACTL3143\": 100, \"ACTL5001\": 50})\n",
    "zhuge = Student(\"Zhuge Liang\", 123456,\n",
    "    {\"ACTL3143\": 100, \"ACTL5001\": 100})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.66666666666667"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "don.wam()\n",
    "#syntax is object.method()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on method wam in module __main__:\n",
      "\n",
      "wam() method of __main__.Student instance\n",
      "    Calculate the weighted average mark for this student.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(zhuge.wam)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lambda Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Bert', 'Patrick', 'Josephine']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort students by length of name \n",
    "names = [\"Josephine\", \"Patrick\", \"Bert\"]\n",
    "sorted(names, key=len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Patrick', 'Bert', 'Josephine']"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sort students by second letter using new function\n",
    "def secondLetter(name):\n",
    "    return name[1]\n",
    "\n",
    "sorted(names, key=secondLetter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Patrick', 'Bert', 'Josephine']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sort students by second letter using a lambda function\n",
    "sorted(names, key=lambda name: name[1])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c931f5753cb3acf1f4642c0cfb5a159d24101420bc9fe73ae8953710c0fa058b"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
