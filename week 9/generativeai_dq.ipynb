{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 9 Discussion Question"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://dev.to/demetrakopetros/generating-beatles-like-lyrics-with-rnns-48ki\n",
    "https://www.tensorflow.org/text/tutorials/text_generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasource: https://www.kaggle.com/datasets/PromptCloudHQ/taylor-swift-song-lyrics-from-all-the-albums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not Path(\"lyricsText.txt\").exists():\n",
    "    print(\"Downloading dataset\")\n",
    "    !wget https://github.com/kchu1711/actl3143/blob/a1e55f150a0dedf6360d206f666b52f4425843d2/assignment/Mx_1x1.txt\n",
    "\n",
    "text = open('lyricsText.txt', 'rb').read().decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocess corpus by:\n",
    "- Convert all letters to lowercase\n",
    "- Remove blank lines\n",
    "- Remove special characters (such as ',' , '(' , ')' , '[' , ']' etc)\n",
    "\n",
    "And then convert to list of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopChars = [',','(',')','.','-','[',']','\"']\n",
    "# preprocessing the corpus by converting all letters to lowercase, \n",
    "# replacing blank lines with blank string and removing special characters\n",
    "def preprocessText(text):\n",
    "  text = text.replace('\\n', ' ').replace('\\t',''). replace('\\r','')\n",
    "  processedText = text.lower()\n",
    "  for char in stopChars:\n",
    "    processedText = processedText.replace(char,'')\n",
    "  return processedText\n",
    "\n",
    "# tokenization\n",
    "def corpusToList(corpus):\n",
    "  corpusList = [w for w in corpus.split(' ')] \n",
    "  corpusList = [i for i in corpusList if i] #removing empty strings from list\n",
    "  return corpusList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<map at 0x1a95d9b44c0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = preprocessText(text)\n",
    "corpus_words = corpusToList(text) \n",
    "map(str.strip, corpus_words) #trim words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Corpus length (in words): 35232\n",
      "Unique words in corpus: 2531\n"
     ]
    }
   ],
   "source": [
    "vocab = sorted(set(corpus_words))\n",
    "print('Corpus length (in words):', len(corpus_words))\n",
    "print('Unique words in corpus: {}'.format(len(vocab)))\n",
    "word2idx = {u: i for i, u in enumerate(vocab)}\n",
    "idx2words = np.array(vocab)\n",
    "word_as_int = np.array([word2idx[c] for c in corpus_words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create training batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset element_spec=(TensorSpec(shape=(64, 10), dtype=tf.int32, name=None), TensorSpec(shape=(64, 10), dtype=tf.int32, name=None))>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The maximum length sentence we want for a single input in words\n",
    "seqLength = 10\n",
    "examples_per_epoch = len(corpus_words)//(seqLength + 1) # number of seqLength+1 sequences in the corpus\n",
    "\n",
    "# Create training / targets batches\n",
    "wordDataset = tf.data.Dataset.from_tensor_slices(word_as_int)\n",
    "sequencesOfWords = wordDataset.batch(seqLength + 1, drop_remainder=True) # generating batches of 10 words each, typically converting list of words (sequence) to string\n",
    "\n",
    "def split_input_target(chunk): # This is where right shift happens\n",
    "  input_text = chunk[:-1]\n",
    "  target_text = chunk[1:]\n",
    "  return input_text, target_text # returns training and target sequence for each batch\n",
    "\n",
    "dataset = sequencesOfWords.map(split_input_target) # dataset now contains a training and a target sequence for each 10 word slice of the corpus\n",
    "\n",
    "# shuffle the batches - prevents RNN from learning the order of the songs in the corpus\n",
    "BATCH_SIZE = 64 # each batch contains 64 sequences. Each sequence contains 10 words (seqLength)\n",
    "BUFFER_SIZE = 100 # Number of batches that will be processed concurrently\n",
    "\n",
    "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our RNN is composed of 3 layers:\n",
    "\n",
    "1. Input layer. It maps the number representing each word to a vector with known dimensions (that are explicitly set)\n",
    "2. GRU (middle) layer: GRU stands for Gated Recurrent Units. The number of units that this layer contains is also explicitly set. This layer could also be replaced by a Long Short-Term Memory (LSTM) layer. \n",
    "3. Output layer: It has as many units as the size of the vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Length of the vocabulary in words\n",
    "vocab_size = len(vocab)\n",
    "# The embedding dimension\n",
    "embedding_dim = 256\n",
    "# Number of GRU units\n",
    "rnn_units = 1024\n",
    "\n",
    "def createModel(vocab_size, embedding_dim, rnn_units, batch_size):\n",
    "    model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim,\n",
    "                                batch_input_shape=[batch_size, None]),\n",
    "    tf.keras.layers.GRU(rnn_units,\n",
    "                        return_sequences=True,\n",
    "                        stateful=True,\n",
    "                        recurrent_initializer='glorot_uniform'),\n",
    "    tf.keras.layers.Dense(vocab_size)\n",
    "    ])\n",
    "    return model\n",
    "\n",
    "model = createModel(vocab_size = len(vocab), embedding_dim=embedding_dim, rnn_units=rnn_units, batch_size=BATCH_SIZE)\n",
    "\n",
    "# loss function\n",
    "def loss(labels, logits):\n",
    "  return tf.keras.losses.sparse_categorical_crossentropy(labels, logits, from_logits=True)\n",
    "model.compile(optimizer='adam', loss=loss)\n",
    "\n",
    "# save checkpoints of training to keep track of progress\n",
    "checkpoint_dir = './training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
    "\n",
    "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_prefix,\n",
    "    save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (64, None, 256)           647936    \n",
      "                                                                 \n",
      " gru_1 (GRU)                 (64, None, 1024)          3938304   \n",
      "                                                                 \n",
      " dense_1 (Dense)             (64, None, 2531)          2594275   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,180,515\n",
      "Trainable params: 7,180,515\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "50/50 [==============================] - 8s 134ms/step - loss: 6.5352\n",
      "Epoch 2/20\n",
      "50/50 [==============================] - 7s 147ms/step - loss: 5.7683\n",
      "Epoch 3/20\n",
      "50/50 [==============================] - 7s 138ms/step - loss: 5.2507\n",
      "Epoch 4/20\n",
      "50/50 [==============================] - 7s 137ms/step - loss: 4.7947\n",
      "Epoch 5/20\n",
      "50/50 [==============================] - 7s 133ms/step - loss: 4.3727\n",
      "Epoch 6/20\n",
      "50/50 [==============================] - 7s 131ms/step - loss: 3.9794\n",
      "Epoch 7/20\n",
      "50/50 [==============================] - 7s 138ms/step - loss: 3.5907\n",
      "Epoch 8/20\n",
      "50/50 [==============================] - 7s 132ms/step - loss: 3.2127\n",
      "Epoch 9/20\n",
      "50/50 [==============================] - 7s 130ms/step - loss: 2.8634\n",
      "Epoch 10/20\n",
      "50/50 [==============================] - 7s 133ms/step - loss: 2.5709\n",
      "Epoch 11/20\n",
      "50/50 [==============================] - 7s 131ms/step - loss: 2.2729\n",
      "Epoch 12/20\n",
      "50/50 [==============================] - 7s 135ms/step - loss: 2.0280\n",
      "Epoch 13/20\n",
      "50/50 [==============================] - 7s 133ms/step - loss: 1.8204\n",
      "Epoch 14/20\n",
      "50/50 [==============================] - 7s 132ms/step - loss: 1.6571\n",
      "Epoch 15/20\n",
      "50/50 [==============================] - 7s 133ms/step - loss: 1.4815\n",
      "Epoch 16/20\n",
      "50/50 [==============================] - 7s 132ms/step - loss: 1.3398\n",
      "Epoch 17/20\n",
      "50/50 [==============================] - 7s 133ms/step - loss: 1.2150\n",
      "Epoch 18/20\n",
      "50/50 [==============================] - 7s 132ms/step - loss: 1.1154\n",
      "Epoch 19/20\n",
      "50/50 [==============================] - 7s 131ms/step - loss: 1.0444\n",
      "Epoch 20/20\n",
      "50/50 [==============================] - 7s 138ms/step - loss: 0.9585\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 20\n",
    "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_2 (Embedding)     (1, None, 256)            647936    \n",
      "                                                                 \n",
      " gru_2 (GRU)                 (1, None, 1024)           3938304   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (1, None, 2531)           2594275   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,180,515\n",
      "Trainable params: 7,180,515\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tf.train.latest_checkpoint(checkpoint_dir)\n",
    "model = createModel(len(vocab), embedding_dim, rnn_units, batch_size=1)\n",
    "\n",
    "model.load_weights(tf.train.latest_checkpoint(checkpoint_dir))\n",
    "\n",
    "model.build(tf.TensorShape([1, None]))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate the lyrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RNNs (as most of Neural network types in general) need an initial state to start predicting.\n",
    "\n",
    "In our case, this initialization is represented by a starting string with which we want the generated lyrics to start.\n",
    "\n",
    "The model generates the probability distribution of the next word using the start string and the RNN state.\n",
    "\n",
    "Then, with the help of categorical distribution, the index of the predicted word is calculated and the predicted word is used as the input for the next time step of the model\n",
    "\n",
    "The state that the RNN returns is then fed back to the input of the RNN, in order to help it by providing more context (not just one word). This process continues as it generates predictions and this is why it learns better while it gets more context from the predicted words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateLyrics(model, startString, temp):\n",
    "  print(f\"---- Generating lyrics starting with '{startString}' with temp {temp} ----\")\n",
    "  # Number of words to generate\n",
    "  num_generate = 30\n",
    "\n",
    "  # Converting our start string to numbers (vectorizing)\n",
    "  start_string_list =  [w for w in startString.split(' ')]\n",
    "  input_eval = [word2idx[s] for s in start_string_list]\n",
    "  input_eval = tf.expand_dims(input_eval, 0)\n",
    "\n",
    "  text_generated = []\n",
    "\n",
    "  model.reset_states()\n",
    "  for i in range(num_generate):\n",
    "      predictions = model(input_eval)\n",
    "      # remove the batch dimension\n",
    "      predictions = tf.squeeze(predictions, 0)\n",
    "\n",
    "      # temp represent how 'conservative' the predictions are. \n",
    "      # Lower temp leads to more predictable (or correct) lyrics\n",
    "      predictions = predictions / temp \n",
    "      predicted_id = tf.random.categorical(predictions, num_samples=1)[-1,0].numpy()\n",
    "\n",
    "      # We pass the predicted word as the next input to the model\n",
    "      # along with the previous hidden state\n",
    "      input_eval = tf.expand_dims([predicted_id], 0)\n",
    "      text_generated.append(' ' + idx2words[predicted_id])\n",
    "  return (startString + ''.join(text_generated))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "Example:\n",
      "---- Generating lyrics starting with 'love' with temp 0.6 ----\n",
      "love affair distance timing breakdown fighting silence ah triptrippin' when you're here so it rains when you're here and it rains when you're gone 'cause i was there to you and\n",
      "Enter start string:\n",
      "Enter temp:\n",
      "---- Generating lyrics starting with 'affair' with temp 0.7 ----\n",
      "affair times well count to ten push me do look what you just made me do look what you just made me do look what you just made me do look\n",
      "Enter start string:\n",
      "Enter temp:\n",
      "---- Generating lyrics starting with 'style' with temp 0.6 ----\n",
      "style we never go out of style we never go out of style we never go out of style we never go out of style we never go out of style\n",
      "Enter start string:\n",
      "Enter temp:\n",
      "---- Generating lyrics starting with 'style' with temp 0.9 ----\n",
      "style that i'm not a princess this ain't a nice little mind i i i shake it off i shake it off shake shake shake shake shake shake shake shake shake\n",
      "Enter start string:\n",
      "Enter temp:\n",
      "---- Generating lyrics starting with 'car' with temp 0.8 ----\n",
      "car ohohoh loving him was red touching him was like realizing all of drop it all eyes and i hope you know that everytime i don't i almost do i have\n",
      "Enter start string:\n",
      "Enter temp:\n",
      "---- Generating lyrics starting with 'fly' with temp 0.6 ----\n",
      "fly whenever you're gone undone you were trouble when you walked in so shame on me now flew me to places i'd never been till you put my baby now i'll\n",
      "Enter start string:\n",
      "Enter temp:\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\kchu1\\Documents\\Coding\\actl3143\\week 9\\generativeai_dq.ipynb Cell 25\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kchu1/Documents/Coding/actl3143/week%209/generativeai_dq.ipynb#ch0000034?line=6'>7</a>\u001b[0m input_str \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m()\u001b[39m.\u001b[39mlower()\u001b[39m.\u001b[39mstrip()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/kchu1/Documents/Coding/actl3143/week%209/generativeai_dq.ipynb#ch0000034?line=7'>8</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mEnter temp:\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/kchu1/Documents/Coding/actl3143/week%209/generativeai_dq.ipynb#ch0000034?line=8'>9</a>\u001b[0m temp \u001b[39m=\u001b[39m \u001b[39mfloat\u001b[39;49m(\u001b[39minput\u001b[39;49m())\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/kchu1/Documents/Coding/actl3143/week%209/generativeai_dq.ipynb#ch0000034?line=9'>10</a>\u001b[0m \u001b[39mprint\u001b[39m(generateLyrics(model, startString\u001b[39m=\u001b[39minput_str, temp\u001b[39m=\u001b[39mtemp))\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: ''"
     ]
    }
   ],
   "source": [
    "#save trained model for future use (so we do not have to train it every time we want to generate text)\n",
    "model.save('saved_model.h5') \n",
    "print(\"Example:\")\n",
    "print(generateLyrics(model, startString=u\"love\", temp=0.6))\n",
    "while (True):\n",
    "  print('Enter start string:')\n",
    "  input_str = input().lower().strip()\n",
    "  print('Enter temp:')\n",
    "  temp = float(input())\n",
    "  print(generateLyrics(model, startString=input_str, temp=temp))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('.env': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "66cd1895dff7263adb7ff11628d05a59612ea005dbfde567253ef0e3682a2146"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
